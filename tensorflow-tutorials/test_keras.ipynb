{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a7e7d2-c8bc-494b-869c-78324af09699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb45948-6aaa-4347-b649-c943dc3fe527",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(2,), name=\"input\")\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"linear\")(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e05f7d29-bd6f-4553-b3d0-e7d3ea43a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.03388441],\n",
      "       [-0.9642005 ]], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1b33376-06e2-4c2c-8b5b-454add80f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x_input, y_input):\n",
    "    x_output = model(x_input)\n",
    "    loss = tf.reduce_mean(tf.square(tf.subtract(x_output, y_input)))\n",
    "    return loss\n",
    "\n",
    "def compute_loss_grads(x_input, y_input):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = calculate_loss(tf.cast(x_input, tf.float32), y_input)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    return loss, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a0ebf15-b3c1-43e5-afb8-231e032e9c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.007948637008667.\n",
      "Loss: 0.8906236290931702.\n",
      "Loss: 0.7869548201560974.\n",
      "Loss: 0.6953533887863159.\n",
      "Loss: 0.614414393901825.\n",
      "Loss: 0.5428965091705322.\n",
      "Loss: 0.4797033667564392.\n",
      "Loss: 0.4238659143447876.\n",
      "Loss: 0.3745279312133789.\n",
      "Loss: 0.33093276619911194.\n",
      "Loss: 0.292412132024765.\n",
      "Loss: 0.25837549567222595.\n",
      "Loss: 0.22830060124397278.\n",
      "Loss: 0.20172637701034546.\n",
      "Loss: 0.1782454550266266.\n",
      "Loss: 0.15749767422676086.\n",
      "Loss: 0.13916495442390442.\n",
      "Loss: 0.12296617776155472.\n",
      "Loss: 0.10865288227796555.\n",
      "Loss: 0.09600567817687988.\n",
      "Loss: 0.08483058214187622.\n",
      "Loss: 0.07495632767677307.\n",
      "Loss: 0.06623134016990662.\n",
      "Loss: 0.0585220530629158.\n",
      "Loss: 0.05171003192663193.\n",
      "Loss: 0.045691002160310745.\n",
      "Loss: 0.0403725765645504.\n",
      "Loss: 0.03567320853471756.\n",
      "Loss: 0.03152085468173027.\n",
      "Loss: 0.02785184234380722.\n",
      "Loss: 0.02460988238453865.\n",
      "Loss: 0.02174525521695614.\n",
      "Loss: 0.019214121624827385.\n",
      "Loss: 0.01697760447859764.\n",
      "Loss: 0.015001388266682625.\n",
      "Loss: 0.013255233876407146.\n",
      "Loss: 0.011712312698364258.\n",
      "Loss: 0.010348990559577942.\n",
      "Loss: 0.009144376963376999.\n",
      "Loss: 0.008079955354332924.\n",
      "Loss: 0.007139456924051046.\n",
      "Loss: 0.006308421492576599.\n",
      "Loss: 0.0055741071701049805.\n",
      "Loss: 0.004925290588289499.\n",
      "Loss: 0.004351970739662647.\n",
      "Loss: 0.0038453941233456135.\n",
      "Loss: 0.0033977802377194166.\n",
      "Loss: 0.0030022859573364258.\n",
      "Loss: 0.0026528111193329096.\n",
      "Loss: 0.0023440299555659294.\n",
      "Loss: 0.0020711866673082113.\n",
      "Loss: 0.0018301013624295592.\n",
      "Loss: 0.0016170748276636004.\n",
      "Loss: 0.0014288545353338122.\n",
      "Loss: 0.0012625313829630613.\n",
      "Loss: 0.001115563907660544.\n",
      "Loss: 0.000985718215815723.\n",
      "Loss: 0.0008709820685908198.\n",
      "Loss: 0.000769606907851994.\n",
      "Loss: 0.0006800240371376276.\n",
      "Loss: 0.0006008641212247312.\n",
      "Loss: 0.0005309265688993037.\n",
      "Loss: 0.00046912333345972.\n",
      "Loss: 0.00041451473953202367.\n",
      "Loss: 0.00036626221844926476.\n",
      "Loss: 0.0003236312768422067.\n",
      "Loss: 0.00028595872572623193.\n",
      "Loss: 0.00025267404271289706.\n",
      "Loss: 0.00022326128964778036.\n",
      "Loss: 0.00019727542530745268.\n",
      "Loss: 0.00017431042215321213.\n",
      "Loss: 0.0001540240045869723.\n",
      "Loss: 0.0001360969472443685.\n",
      "Loss: 0.00012025452451780438.\n",
      "Loss: 0.00010625542927300557.\n",
      "Loss: 9.38900702749379e-05.\n",
      "Loss: 8.296121814055368e-05.\n",
      "Loss: 7.33052656869404e-05.\n",
      "Loss: 6.477122951764613e-05.\n",
      "Loss: 5.723315916839056e-05.\n",
      "Loss: 5.0572438340168446e-05.\n",
      "Loss: 4.4686286855721846e-05.\n",
      "Loss: 3.94826456613373e-05.\n",
      "Loss: 3.488771108095534e-05.\n",
      "Loss: 3.0827945010969415e-05.\n",
      "Loss: 2.723778015933931e-05.\n",
      "Loss: 2.4068238417385146e-05.\n",
      "Loss: 2.1265859686536714e-05.\n",
      "Loss: 1.8790555259329267e-05.\n",
      "Loss: 1.6604091797489673e-05.\n",
      "Loss: 1.46703896461986e-05.\n",
      "Loss: 1.2962585060449783e-05.\n",
      "Loss: 1.1453837032604497e-05.\n",
      "Loss: 1.0120154911419377e-05.\n",
      "Loss: 8.942282875068486e-06.\n",
      "Loss: 7.901468052295968e-06.\n",
      "Loss: 6.981611477385741e-06.\n",
      "Loss: 6.1683003877988085e-06.\n",
      "Loss: 5.450889148050919e-06.\n",
      "Loss: 4.816457931156037e-06.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "for iter in range(100):\n",
    "    loss, grads = compute_loss_grads([[1.0, 1.0]], [2.0])\n",
    "    print(f\"Loss: {loss.numpy()}.\")\n",
    "    optimizer.apply(grads, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0ffb02-a5d0-477d-beb5-f788a44be7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1.0099691 ],\n",
      "       [0.01188363]], dtype=float32), array([0.9760843], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0a37a-1b94-4623-8be4-1d8e971984b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
