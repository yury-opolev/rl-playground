{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5a7e7d2-c8bc-494b-869c-78324af09699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensorflow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebb45948-6aaa-4347-b649-c943dc3fe527",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(2,), name=\"input\")\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"linear\")(inputs)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1b33376-06e2-4c2c-8b5b-454add80f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(x_input, y_input):\n",
    "    x_output = model(x_input)\n",
    "    loss = tf.reduce_mean(tf.square(tf.subtract(x_output, y_input)))\n",
    "    return loss\n",
    "\n",
    "def compute_loss_grads(x_input, y_input):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = calculate_loss(tf.cast(x_input, tf.float32), y_input)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    return loss, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a0ebf15-b3c1-43e5-afb8-231e032e9c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.7850162982940674.\n",
      "Loss: 2.4608402252197266.\n",
      "Loss: 2.17439866065979.\n",
      "Loss: 1.9212985038757324.\n",
      "Loss: 1.6976594924926758.\n",
      "Loss: 1.500051736831665.\n",
      "Loss: 1.3254457712173462.\n",
      "Loss: 1.1711639165878296.\n",
      "Loss: 1.0348403453826904.\n",
      "Loss: 0.9143850207328796.\n",
      "Loss: 0.8079505562782288.\n",
      "Loss: 0.7139051556587219.\n",
      "Loss: 0.630806565284729.\n",
      "Loss: 0.557380735874176.\n",
      "Loss: 0.4925016462802887.\n",
      "Loss: 0.4351744055747986.\n",
      "Loss: 0.38452011346817017.\n",
      "Loss: 0.33976197242736816.\n",
      "Loss: 0.30021363496780396.\n",
      "Loss: 0.26526883244514465.\n",
      "Loss: 0.23439152538776398.\n",
      "Loss: 0.20710836350917816.\n",
      "Loss: 0.18300090730190277.\n",
      "Loss: 0.16169962286949158.\n",
      "Loss: 0.14287780225276947.\n",
      "Loss: 0.12624682486057281.\n",
      "Loss: 0.1115516945719719.\n",
      "Loss: 0.09856707602739334.\n",
      "Loss: 0.08709384500980377.\n",
      "Loss: 0.0769561231136322.\n",
      "Loss: 0.06799845397472382.\n",
      "Loss: 0.060083430260419846.\n",
      "Loss: 0.0530896931886673.\n",
      "Loss: 0.046910062432289124.\n",
      "Loss: 0.04144972935318947.\n",
      "Loss: 0.03662499040365219.\n",
      "Loss: 0.03236183896660805.\n",
      "Loss: 0.028594905510544777.\n",
      "Loss: 0.025266475975513458.\n",
      "Loss: 0.02232545241713524.\n",
      "Loss: 0.019726771861314774.\n",
      "Loss: 0.017430584877729416.\n",
      "Loss: 0.015401660464704037.\n",
      "Loss: 0.013608915731310844.\n",
      "Loss: 0.012024838477373123.\n",
      "Loss: 0.010625149123370647.\n",
      "Loss: 0.00938838254660368.\n",
      "Loss: 0.008295578882098198.\n",
      "Loss: 0.007329975720494986.\n",
      "Loss: 0.006476768292486668.\n",
      "Loss: 0.005722873844206333.\n",
      "Loss: 0.00505672674626112.\n",
      "Loss: 0.00446811830624938.\n",
      "Loss: 0.0039480323903262615.\n",
      "Loss: 0.003488489193841815.\n",
      "Loss: 0.003082423936575651.\n",
      "Loss: 0.0027236349415034056.\n",
      "Loss: 0.0024066015612334013.\n",
      "Loss: 0.0021264704409986734.\n",
      "Loss: 0.0018789521418511868.\n",
      "Loss: 0.0016602391842752695.\n",
      "Loss: 0.0014669887023046613.\n",
      "Loss: 0.0012962283799424767.\n",
      "Loss: 0.0011453473707661033.\n",
      "Loss: 0.001012026914395392.\n",
      "Loss: 0.0008942282875068486.\n",
      "Loss: 0.000790140125900507.\n",
      "Loss: 0.0006981674232520163.\n",
      "Loss: 0.0006169010885059834.\n",
      "Loss: 0.0005450944881886244.\n",
      "Loss: 0.00048164580948650837.\n",
      "Loss: 0.00042558222776278853.\n",
      "Loss: 0.00037604555836878717.\n",
      "Loss: 0.00033227281528525054.\n",
      "Loss: 0.00029359679319895804.\n",
      "Loss: 0.0002594227553345263.\n",
      "Loss: 0.00022922673088032752.\n",
      "Loss: 0.0002025458525167778.\n",
      "Loss: 0.00017896993085741997.\n",
      "Loss: 0.00015813737991265953.\n",
      "Loss: 0.0001397297455696389.\n",
      "Loss: 0.0001234653900610283.\n",
      "Loss: 0.0001090955120162107.\n",
      "Loss: 9.639580821385607e-05.\n",
      "Loss: 8.517561946064234e-05.\n",
      "Loss: 7.526147237513214e-05.\n",
      "Loss: 6.649994611507282e-05.\n",
      "Loss: 5.876012073713355e-05.\n",
      "Loss: 5.1920749683631584e-05.\n",
      "Loss: 4.587669172906317e-05.\n",
      "Loss: 4.053676457260735e-05.\n",
      "Loss: 3.581834243959747e-05.\n",
      "Loss: 3.164945155731402e-05.\n",
      "Loss: 2.7965517801931128e-05.\n",
      "Loss: 2.470992876624223e-05.\n",
      "Loss: 2.1833626306033693e-05.\n",
      "Loss: 1.9292003344162367e-05.\n",
      "Loss: 1.7046610082616098e-05.\n",
      "Loss: 1.5062450074765366e-05.\n",
      "Loss: 1.3309085261425935e-05.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "for iter in range(100):\n",
    "    loss, grads = compute_loss_grads([[1.0, 1.0]], [1.0])\n",
    "    print(f\"Loss: {loss.numpy()}.\")\n",
    "    optimizer.apply(grads, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ffb02-a5d0-477d-beb5-f788a44be7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
